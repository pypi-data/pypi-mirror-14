# Generated from ElasticsearchGrammar.g4 by ANTLR 4.5.1
# encoding: utf-8
from __future__ import print_function
from antlr4 import *
from io import StringIO

def serializedATN():
    with StringIO() as buf:
        buf.write(u"\3\u0430\ud6d1\u8206\uad2d\u4417\uaef1\u8d80\uaadd\3")
        buf.write(u"\60\u010c\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7")
        buf.write(u"\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t")
        buf.write(u"\r\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22")
        buf.write(u"\4\23\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4")
        buf.write(u"\30\t\30\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35")
        buf.write(u"\t\35\3\2\3\2\5\2=\n\2\3\3\3\3\3\3\3\4\5\4C\n\4\3\4\3")
        buf.write(u"\4\5\4G\n\4\3\4\3\4\3\5\3\5\5\5M\n\5\3\5\7\5P\n\5\f\5")
        buf.write(u"\16\5S\13\5\3\6\3\6\3\6\3\6\7\6Y\n\6\f\6\16\6\\\13\6")
        buf.write(u"\3\7\3\7\3\7\3\7\7\7b\n\7\f\7\16\7e\13\7\3\b\3\b\3\b")
        buf.write(u"\3\b\7\bk\n\b\f\b\16\bn\13\b\3\t\5\tq\n\t\3\t\5\tt\n")
        buf.write(u"\t\3\t\3\t\3\t\5\ty\n\t\3\t\3\t\5\t}\n\t\3\t\5\t\u0080")
        buf.write(u"\n\t\3\t\5\t\u0083\n\t\3\n\5\n\u0086\n\n\3\n\3\n\3\n")
        buf.write(u"\5\n\u008b\n\n\3\n\5\n\u008e\n\n\3\n\5\n\u0091\n\n\3")
        buf.write(u"\n\3\n\5\n\u0095\n\n\5\n\u0097\n\n\3\13\3\13\3\13\5\13")
        buf.write(u"\u009c\n\13\3\f\3\f\3\f\3\f\3\f\3\f\3\f\3\f\5\f\u00a6")
        buf.write(u"\n\f\3\r\3\r\3\r\3\r\3\16\3\16\5\16\u00ae\n\16\3\16\3")
        buf.write(u"\16\5\16\u00b2\n\16\3\16\5\16\u00b5\n\16\3\16\5\16\u00b8")
        buf.write(u"\n\16\3\16\3\16\5\16\u00bc\n\16\5\16\u00be\n\16\3\16")
        buf.write(u"\3\16\3\17\3\17\3\17\3\17\3\17\3\17\5\17\u00c8\n\17\3")
        buf.write(u"\20\3\20\3\20\5\20\u00cd\n\20\3\20\3\20\3\21\3\21\3\22")
        buf.write(u"\3\22\3\23\3\23\3\24\3\24\3\25\3\25\3\26\3\26\5\26\u00dd")
        buf.write(u"\n\26\3\26\3\26\5\26\u00e1\n\26\5\26\u00e3\n\26\3\27")
        buf.write(u"\3\27\5\27\u00e7\n\27\3\30\3\30\5\30\u00eb\n\30\3\31")
        buf.write(u"\5\31\u00ee\n\31\3\31\3\31\5\31\u00f2\n\31\3\31\3\31")
        buf.write(u"\5\31\u00f6\n\31\3\31\5\31\u00f9\n\31\3\32\5\32\u00fc")
        buf.write(u"\n\32\3\32\3\32\3\33\5\33\u0101\n\33\3\33\3\33\3\34\3")
        buf.write(u"\34\3\35\6\35\u0108\n\35\r\35\16\35\u0109\3\35\2\2\36")
        buf.write(u"\2\4\6\b\n\f\16\20\22\24\26\30\32\34\36 \"$&(*,.\60\62")
        buf.write(u"\64\668\2\7\3\2\3\6\4\2\t\t\20\20\4\2\n\n\21\21\4\2\33")
        buf.write(u"\33\35\35\3\2\f\r\u0123\2<\3\2\2\2\4>\3\2\2\2\6B\3\2")
        buf.write(u"\2\2\bJ\3\2\2\2\nT\3\2\2\2\f]\3\2\2\2\16f\3\2\2\2\20")
        buf.write(u"\u0082\3\2\2\2\22\u0096\3\2\2\2\24\u0098\3\2\2\2\26\u00a5")
        buf.write(u"\3\2\2\2\30\u00a7\3\2\2\2\32\u00ab\3\2\2\2\34\u00c7\3")
        buf.write(u"\2\2\2\36\u00c9\3\2\2\2 \u00d0\3\2\2\2\"\u00d2\3\2\2")
        buf.write(u"\2$\u00d4\3\2\2\2&\u00d6\3\2\2\2(\u00d8\3\2\2\2*\u00e2")
        buf.write(u"\3\2\2\2,\u00e4\3\2\2\2.\u00e8\3\2\2\2\60\u00f8\3\2\2")
        buf.write(u"\2\62\u00fb\3\2\2\2\64\u0100\3\2\2\2\66\u0104\3\2\2\2")
        buf.write(u"8\u0107\3\2\2\2:=\5\32\16\2;=\5\4\3\2<:\3\2\2\2<;\3\2")
        buf.write(u"\2\2=\3\3\2\2\2>?\t\2\2\2?@\5\34\17\2@\5\3\2\2\2AC\5")
        buf.write(u"8\35\2BA\3\2\2\2BC\3\2\2\2CD\3\2\2\2DF\5\b\5\2EG\58\35")
        buf.write(u"\2FE\3\2\2\2FG\3\2\2\2GH\3\2\2\2HI\7\2\2\3I\7\3\2\2\2")
        buf.write(u"JQ\5\n\6\2KM\58\35\2LK\3\2\2\2LM\3\2\2\2MN\3\2\2\2NP")
        buf.write(u"\5\n\6\2OL\3\2\2\2PS\3\2\2\2QO\3\2\2\2QR\3\2\2\2R\t\3")
        buf.write(u"\2\2\2SQ\3\2\2\2TZ\5\f\7\2UV\5\64\33\2VW\5\f\7\2WY\3")
        buf.write(u"\2\2\2XU\3\2\2\2Y\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[\13\3")
        buf.write(u"\2\2\2\\Z\3\2\2\2]c\5\16\b\2^_\5\62\32\2_`\5\16\b\2`")
        buf.write(u"b\3\2\2\2a^\3\2\2\2be\3\2\2\2ca\3\2\2\2cd\3\2\2\2d\r")
        buf.write(u"\3\2\2\2ec\3\2\2\2fl\5\20\t\2gh\5\60\31\2hi\5\20\t\2")
        buf.write(u"ik\3\2\2\2jg\3\2\2\2kn\3\2\2\2lj\3\2\2\2lm\3\2\2\2m\17")
        buf.write(u"\3\2\2\2nl\3\2\2\2oq\58\35\2po\3\2\2\2pq\3\2\2\2qs\3")
        buf.write(u"\2\2\2rt\5(\25\2sr\3\2\2\2st\3\2\2\2tu\3\2\2\2uv\7\7")
        buf.write(u"\2\2vx\5\b\5\2wy\58\35\2xw\3\2\2\2xy\3\2\2\2yz\3\2\2")
        buf.write(u"\2z|\7\b\2\2{}\5*\26\2|{\3\2\2\2|}\3\2\2\2}\u0083\3\2")
        buf.write(u"\2\2~\u0080\58\35\2\177~\3\2\2\2\177\u0080\3\2\2\2\u0080")
        buf.write(u"\u0081\3\2\2\2\u0081\u0083\5\22\n\2\u0082p\3\2\2\2\u0082")
        buf.write(u"\177\3\2\2\2\u0083\21\3\2\2\2\u0084\u0086\5(\25\2\u0085")
        buf.write(u"\u0084\3\2\2\2\u0085\u0086\3\2\2\2\u0086\u0087\3\2\2")
        buf.write(u"\2\u0087\u0088\5\24\13\2\u0088\u008a\5\36\20\2\u0089")
        buf.write(u"\u008b\5*\26\2\u008a\u0089\3\2\2\2\u008a\u008b\3\2\2")
        buf.write(u"\2\u008b\u0097\3\2\2\2\u008c\u008e\5(\25\2\u008d\u008c")
        buf.write(u"\3\2\2\2\u008d\u008e\3\2\2\2\u008e\u0090\3\2\2\2\u008f")
        buf.write(u"\u0091\5\24\13\2\u0090\u008f\3\2\2\2\u0090\u0091\3\2")
        buf.write(u"\2\2\u0091\u0092\3\2\2\2\u0092\u0094\5\26\f\2\u0093\u0095")
        buf.write(u"\5*\26\2\u0094\u0093\3\2\2\2\u0094\u0095\3\2\2\2\u0095")
        buf.write(u"\u0097\3\2\2\2\u0096\u0085\3\2\2\2\u0096\u008d\3\2\2")
        buf.write(u"\2\u0097\23\3\2\2\2\u0098\u0099\7\35\2\2\u0099\u009b")
        buf.write(u"\7\13\2\2\u009a\u009c\58\35\2\u009b\u009a\3\2\2\2\u009b")
        buf.write(u"\u009c\3\2\2\2\u009c\25\3\2\2\2\u009d\u00a6\5\2\2\2\u009e")
        buf.write(u"\u00a6\5 \21\2\u009f\u00a6\5\"\22\2\u00a0\u00a6\5&\24")
        buf.write(u"\2\u00a1\u00a6\5$\23\2\u00a2\u00a6\7\17\2\2\u00a3\u00a6")
        buf.write(u"\5\30\r\2\u00a4\u00a6\7\16\2\2\u00a5\u009d\3\2\2\2\u00a5")
        buf.write(u"\u009e\3\2\2\2\u00a5\u009f\3\2\2\2\u00a5\u00a0\3\2\2")
        buf.write(u"\2\u00a5\u00a1\3\2\2\2\u00a5\u00a2\3\2\2\2\u00a5\u00a3")
        buf.write(u"\3\2\2\2\u00a5\u00a4\3\2\2\2\u00a6\27\3\2\2\2\u00a7\u00a8")
        buf.write(u"\7\16\2\2\u00a8\u00a9\7\13\2\2\u00a9\u00aa\7\16\2\2\u00aa")
        buf.write(u"\31\3\2\2\2\u00ab\u00ad\t\3\2\2\u00ac\u00ae\58\35\2\u00ad")
        buf.write(u"\u00ac\3\2\2\2\u00ad\u00ae\3\2\2\2\u00ae\u00af\3\2\2")
        buf.write(u"\2\u00af\u00b1\5\34\17\2\u00b0\u00b2\58\35\2\u00b1\u00b0")
        buf.write(u"\3\2\2\2\u00b1\u00b2\3\2\2\2\u00b2\u00bd\3\2\2\2\u00b3")
        buf.write(u"\u00b5\7\26\2\2\u00b4\u00b3\3\2\2\2\u00b4\u00b5\3\2\2")
        buf.write(u"\2\u00b5\u00b7\3\2\2\2\u00b6\u00b8\58\35\2\u00b7\u00b6")
        buf.write(u"\3\2\2\2\u00b7\u00b8\3\2\2\2\u00b8\u00b9\3\2\2\2\u00b9")
        buf.write(u"\u00bb\5\34\17\2\u00ba\u00bc\58\35\2\u00bb\u00ba\3\2")
        buf.write(u"\2\2\u00bb\u00bc\3\2\2\2\u00bc\u00be\3\2\2\2\u00bd\u00b4")
        buf.write(u"\3\2\2\2\u00bd\u00be\3\2\2\2\u00be\u00bf\3\2\2\2\u00bf")
        buf.write(u"\u00c0\t\4\2\2\u00c0\33\3\2\2\2\u00c1\u00c8\5\"\22\2")
        buf.write(u"\u00c2\u00c8\5&\24\2\u00c3\u00c8\5$\23\2\u00c4\u00c8")
        buf.write(u"\5\66\34\2\u00c5\u00c8\5 \21\2\u00c6\u00c8\7\16\2\2\u00c7")
        buf.write(u"\u00c1\3\2\2\2\u00c7\u00c2\3\2\2\2\u00c7\u00c3\3\2\2")
        buf.write(u"\2\u00c7\u00c4\3\2\2\2\u00c7\u00c5\3\2\2\2\u00c7\u00c6")
        buf.write(u"\3\2\2\2\u00c8\35\3\2\2\2\u00c9\u00ca\7\7\2\2\u00ca\u00cc")
        buf.write(u"\5\b\5\2\u00cb\u00cd\58\35\2\u00cc\u00cb\3\2\2\2\u00cc")
        buf.write(u"\u00cd\3\2\2\2\u00cd\u00ce\3\2\2\2\u00ce\u00cf\7\b\2")
        buf.write(u"\2\u00cf\37\3\2\2\2\u00d0\u00d1\t\5\2\2\u00d1!\3\2\2")
        buf.write(u"\2\u00d2\u00d3\7\36\2\2\u00d3#\3\2\2\2\u00d4\u00d5\7")
        buf.write(u" \2\2\u00d5%\3\2\2\2\u00d6\u00d7\7\37\2\2\u00d7\'\3\2")
        buf.write(u"\2\2\u00d8\u00d9\t\6\2\2\u00d9)\3\2\2\2\u00da\u00dc\5")
        buf.write(u",\27\2\u00db\u00dd\5.\30\2\u00dc\u00db\3\2\2\2\u00dc")
        buf.write(u"\u00dd\3\2\2\2\u00dd\u00e3\3\2\2\2\u00de\u00e0\5.\30")
        buf.write(u"\2\u00df\u00e1\5,\27\2\u00e0\u00df\3\2\2\2\u00e0\u00e1")
        buf.write(u"\3\2\2\2\u00e1\u00e3\3\2\2\2\u00e2\u00da\3\2\2\2\u00e2")
        buf.write(u"\u00de\3\2\2\2\u00e3+\3\2\2\2\u00e4\u00e6\7\22\2\2\u00e5")
        buf.write(u"\u00e7\7\33\2\2\u00e6\u00e5\3\2\2\2\u00e6\u00e7\3\2\2")
        buf.write(u"\2\u00e7-\3\2\2\2\u00e8\u00ea\7\23\2\2\u00e9\u00eb\7")
        buf.write(u"\33\2\2\u00ea\u00e9\3\2\2\2\u00ea\u00eb\3\2\2\2\u00eb")
        buf.write(u"/\3\2\2\2\u00ec\u00ee\58\35\2\u00ed\u00ec\3\2\2\2\u00ed")
        buf.write(u"\u00ee\3\2\2\2\u00ee\u00ef\3\2\2\2\u00ef\u00f1\7\27\2")
        buf.write(u"\2\u00f0\u00f2\58\35\2\u00f1\u00f0\3\2\2\2\u00f1\u00f2")
        buf.write(u"\3\2\2\2\u00f2\u00f3\3\2\2\2\u00f3\u00f9\7\31\2\2\u00f4")
        buf.write(u"\u00f6\58\35\2\u00f5\u00f4\3\2\2\2\u00f5\u00f6\3\2\2")
        buf.write(u"\2\u00f6\u00f7\3\2\2\2\u00f7\u00f9\7\31\2\2\u00f8\u00ed")
        buf.write(u"\3\2\2\2\u00f8\u00f5\3\2\2\2\u00f9\61\3\2\2\2\u00fa\u00fc")
        buf.write(u"\58\35\2\u00fb\u00fa\3\2\2\2\u00fb\u00fc\3\2\2\2\u00fc")
        buf.write(u"\u00fd\3\2\2\2\u00fd\u00fe\7\27\2\2\u00fe\63\3\2\2\2")
        buf.write(u"\u00ff\u0101\58\35\2\u0100\u00ff\3\2\2\2\u0100\u0101")
        buf.write(u"\3\2\2\2\u0101\u0102\3\2\2\2\u0102\u0103\7\30\2\2\u0103")
        buf.write(u"\65\3\2\2\2\u0104\u0105\7\34\2\2\u0105\67\3\2\2\2\u0106")
        buf.write(u"\u0108\7\32\2\2\u0107\u0106\3\2\2\2\u0108\u0109\3\2\2")
        buf.write(u"\2\u0109\u0107\3\2\2\2\u0109\u010a\3\2\2\2\u010a9\3\2")
        buf.write(u"\2\2,<BFLQZclpsx|\177\u0082\u0085\u008a\u008d\u0090\u0094")
        buf.write(u"\u0096\u009b\u00a5\u00ad\u00b1\u00b4\u00b7\u00bb\u00bd")
        buf.write(u"\u00c7\u00cc\u00dc\u00e0\u00e2\u00e6\u00ea\u00ed\u00f1")
        buf.write(u"\u00f5\u00f8\u00fb\u0100\u0109")
        return buf.getvalue()


class ElasticsearchGrammarParser ( Parser ):

    grammarFileName = "ElasticsearchGrammar.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ u"<INVALID>", u"'>'", u"'>='", u"'<'", u"'<='", u"'('", 
                     u"')'", u"'['", u"']'", u"':'", u"'+'", u"<INVALID>", 
                     u"'*'", u"<INVALID>", u"'{'", u"'}'", u"<INVALID>", 
                     u"<INVALID>", u"'\"'", u"'''", u"'TO'" ]

    symbolicNames = [ u"<INVALID>", u"GT", u"GTE", u"LT", u"LTE", u"LPAREN", 
                      u"RPAREN", u"LBRACK", u"RBRACK", u"COLON", u"PLUS", 
                      u"MINUS", u"STAR", u"QMARK", u"LCURLY", u"RCURLY", 
                      u"CARAT", u"TILDE", u"DQUOTE", u"SQUOTE", u"TO", u"AND", 
                      u"OR", u"NOT", u"WS", u"NUMBER", u"DATE_TOKEN", u"TERM_NORMAL", 
                      u"TERM_TRUNCATED", u"PHRASE", u"PHRASE_ANYTHING", 
                      u"OPERATOR", u"ATOM", u"MODIFIER", u"TMODIFIER", u"CLAUSE", 
                      u"FIELD", u"FUZZY", u"BOOST", u"QNORMAL", u"QPHRASE", 
                      u"QPHRASETRUNC", u"QTRUNCATED", u"QRANGEIN", u"QRANGEEX", 
                      u"QANYTHING", u"QDATE" ]

    RULE_range_term = 0
    RULE_one_sided_range_term = 1
    RULE_mainQ = 2
    RULE_clauseDefault = 3
    RULE_clauseOr = 4
    RULE_clauseAnd = 5
    RULE_clauseNot = 6
    RULE_clauseBasic = 7
    RULE_atom = 8
    RULE_field = 9
    RULE_value = 10
    RULE_anything = 11
    RULE_two_sided_range_term = 12
    RULE_range_value = 13
    RULE_multi_value = 14
    RULE_normal = 15
    RULE_truncated = 16
    RULE_quoted_truncated = 17
    RULE_quoted = 18
    RULE_modifier = 19
    RULE_term_modifier = 20
    RULE_boost = 21
    RULE_fuzzy = 22
    RULE_not_ = 23
    RULE_and_ = 24
    RULE_or_ = 25
    RULE_date = 26
    RULE_sep = 27

    ruleNames =  [ u"range_term", u"one_sided_range_term", u"mainQ", u"clauseDefault", 
                   u"clauseOr", u"clauseAnd", u"clauseNot", u"clauseBasic", 
                   u"atom", u"field", u"value", u"anything", u"two_sided_range_term", 
                   u"range_value", u"multi_value", u"normal", u"truncated", 
                   u"quoted_truncated", u"quoted", u"modifier", u"term_modifier", 
                   u"boost", u"fuzzy", u"not_", u"and_", u"or_", u"date", 
                   u"sep" ]

    EOF = Token.EOF
    GT=1
    GTE=2
    LT=3
    LTE=4
    LPAREN=5
    RPAREN=6
    LBRACK=7
    RBRACK=8
    COLON=9
    PLUS=10
    MINUS=11
    STAR=12
    QMARK=13
    LCURLY=14
    RCURLY=15
    CARAT=16
    TILDE=17
    DQUOTE=18
    SQUOTE=19
    TO=20
    AND=21
    OR=22
    NOT=23
    WS=24
    NUMBER=25
    DATE_TOKEN=26
    TERM_NORMAL=27
    TERM_TRUNCATED=28
    PHRASE=29
    PHRASE_ANYTHING=30
    OPERATOR=31
    ATOM=32
    MODIFIER=33
    TMODIFIER=34
    CLAUSE=35
    FIELD=36
    FUZZY=37
    BOOST=38
    QNORMAL=39
    QPHRASE=40
    QPHRASETRUNC=41
    QTRUNCATED=42
    QRANGEIN=43
    QRANGEEX=44
    QANYTHING=45
    QDATE=46

    def __init__(self, input):
        super(ElasticsearchGrammarParser, self).__init__(input)
        self.checkVersion("4.5.1")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None



    class Range_termContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.Range_termContext, self).__init__(parent, invokingState)
            self.parser = parser

        def two_sided_range_term(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.Two_sided_range_termContext,0)


        def one_sided_range_term(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.One_sided_range_termContext,0)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_range_term

        def enterRule(self, listener):
            if hasattr(listener, "enterRange_term"):
                listener.enterRange_term(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitRange_term"):
                listener.exitRange_term(self)




    def range_term(self):

        localctx = ElasticsearchGrammarParser.Range_termContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_range_term)
        try:
            self.state = 58
            token = self._input.LA(1)
            if token in [ElasticsearchGrammarParser.LBRACK, ElasticsearchGrammarParser.LCURLY]:
                self.enterOuterAlt(localctx, 1)
                self.state = 56
                self.two_sided_range_term()

            elif token in [ElasticsearchGrammarParser.GT, ElasticsearchGrammarParser.GTE, ElasticsearchGrammarParser.LT, ElasticsearchGrammarParser.LTE]:
                self.enterOuterAlt(localctx, 2)
                self.state = 57
                self.one_sided_range_term()

            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class One_sided_range_termContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.One_sided_range_termContext, self).__init__(parent, invokingState)
            self.parser = parser
            self.op = None # Token
            self.val = None # Range_valueContext

        def range_value(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.Range_valueContext,0)


        def GT(self):
            return self.getToken(ElasticsearchGrammarParser.GT, 0)

        def GTE(self):
            return self.getToken(ElasticsearchGrammarParser.GTE, 0)

        def LT(self):
            return self.getToken(ElasticsearchGrammarParser.LT, 0)

        def LTE(self):
            return self.getToken(ElasticsearchGrammarParser.LTE, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_one_sided_range_term

        def enterRule(self, listener):
            if hasattr(listener, "enterOne_sided_range_term"):
                listener.enterOne_sided_range_term(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitOne_sided_range_term"):
                listener.exitOne_sided_range_term(self)




    def one_sided_range_term(self):

        localctx = ElasticsearchGrammarParser.One_sided_range_termContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_one_sided_range_term)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 60
            localctx.op = self._input.LT(1)
            _la = self._input.LA(1)
            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << ElasticsearchGrammarParser.GT) | (1 << ElasticsearchGrammarParser.GTE) | (1 << ElasticsearchGrammarParser.LT) | (1 << ElasticsearchGrammarParser.LTE))) != 0)):
                localctx.op = self._errHandler.recoverInline(self)
            else:
                self.consume()
            self.state = 61
            localctx.val = self.range_value()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class MainQContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.MainQContext, self).__init__(parent, invokingState)
            self.parser = parser
            self.clause = None # ClauseDefaultContext

        def EOF(self):
            return self.getToken(ElasticsearchGrammarParser.EOF, 0)

        def clauseDefault(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.ClauseDefaultContext,0)


        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,i)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_mainQ

        def enterRule(self, listener):
            if hasattr(listener, "enterMainQ"):
                listener.enterMainQ(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitMainQ"):
                listener.exitMainQ(self)




    def mainQ(self):

        localctx = ElasticsearchGrammarParser.MainQContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_mainQ)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 64
            la_ = self._interp.adaptivePredict(self._input,1,self._ctx)
            if la_ == 1:
                self.state = 63
                self.sep()


            self.state = 66
            localctx.clause = self.clauseDefault()
            self.state = 68
            _la = self._input.LA(1)
            if _la==ElasticsearchGrammarParser.WS:
                self.state = 67
                self.sep()


            self.state = 70
            self.match(ElasticsearchGrammarParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseDefaultContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.ClauseDefaultContext, self).__init__(parent, invokingState)
            self.parser = parser

        def clauseOr(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.ClauseOrContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.ClauseOrContext,i)


        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,i)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_clauseDefault

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseDefault"):
                listener.enterClauseDefault(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseDefault"):
                listener.exitClauseDefault(self)




    def clauseDefault(self):

        localctx = ElasticsearchGrammarParser.ClauseDefaultContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_clauseDefault)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 72
            self.clauseOr()
            self.state = 79
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,4,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 74
                    la_ = self._interp.adaptivePredict(self._input,3,self._ctx)
                    if la_ == 1:
                        self.state = 73
                        self.sep()


                    self.state = 76
                    self.clauseOr() 
                self.state = 81
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,4,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseOrContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.ClauseOrContext, self).__init__(parent, invokingState)
            self.parser = parser

        def clauseAnd(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.ClauseAndContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.ClauseAndContext,i)


        def or_(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.Or_Context)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.Or_Context,i)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_clauseOr

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseOr"):
                listener.enterClauseOr(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseOr"):
                listener.exitClauseOr(self)




    def clauseOr(self):

        localctx = ElasticsearchGrammarParser.ClauseOrContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_clauseOr)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 82
            self.clauseAnd()
            self.state = 88
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 83
                    self.or_()
                    self.state = 84
                    self.clauseAnd() 
                self.state = 90
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,5,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseAndContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.ClauseAndContext, self).__init__(parent, invokingState)
            self.parser = parser

        def clauseNot(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.ClauseNotContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.ClauseNotContext,i)


        def and_(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.And_Context)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.And_Context,i)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_clauseAnd

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseAnd"):
                listener.enterClauseAnd(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseAnd"):
                listener.exitClauseAnd(self)




    def clauseAnd(self):

        localctx = ElasticsearchGrammarParser.ClauseAndContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_clauseAnd)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 91
            self.clauseNot()
            self.state = 97
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,6,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 92
                    self.and_()
                    self.state = 93
                    self.clauseNot() 
                self.state = 99
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,6,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseNotContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.ClauseNotContext, self).__init__(parent, invokingState)
            self.parser = parser

        def clauseBasic(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.ClauseBasicContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.ClauseBasicContext,i)


        def not_(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.Not_Context)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.Not_Context,i)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_clauseNot

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseNot"):
                listener.enterClauseNot(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseNot"):
                listener.exitClauseNot(self)




    def clauseNot(self):

        localctx = ElasticsearchGrammarParser.ClauseNotContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_clauseNot)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 100
            self.clauseBasic()
            self.state = 106
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,7,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 101
                    self.not_()
                    self.state = 102
                    self.clauseBasic() 
                self.state = 108
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,7,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseBasicContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.ClauseBasicContext, self).__init__(parent, invokingState)
            self.parser = parser

        def LPAREN(self):
            return self.getToken(ElasticsearchGrammarParser.LPAREN, 0)

        def clauseDefault(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.ClauseDefaultContext,0)


        def RPAREN(self):
            return self.getToken(ElasticsearchGrammarParser.RPAREN, 0)

        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,i)


        def modifier(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.ModifierContext,0)


        def term_modifier(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.Term_modifierContext,0)


        def atom(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.AtomContext,0)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_clauseBasic

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseBasic"):
                listener.enterClauseBasic(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseBasic"):
                listener.exitClauseBasic(self)




    def clauseBasic(self):

        localctx = ElasticsearchGrammarParser.ClauseBasicContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_clauseBasic)
        self._la = 0 # Token type
        try:
            self.state = 128
            la_ = self._interp.adaptivePredict(self._input,13,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 110
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.WS:
                    self.state = 109
                    self.sep()


                self.state = 113
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.PLUS or _la==ElasticsearchGrammarParser.MINUS:
                    self.state = 112
                    self.modifier()


                self.state = 115
                self.match(ElasticsearchGrammarParser.LPAREN)
                self.state = 116
                self.clauseDefault()
                self.state = 118
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.WS:
                    self.state = 117
                    self.sep()


                self.state = 120
                self.match(ElasticsearchGrammarParser.RPAREN)
                self.state = 122
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.CARAT or _la==ElasticsearchGrammarParser.TILDE:
                    self.state = 121
                    self.term_modifier()


                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 125
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.WS:
                    self.state = 124
                    self.sep()


                self.state = 127
                self.atom()
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class AtomContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.AtomContext, self).__init__(parent, invokingState)
            self.parser = parser

        def field(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.FieldContext,0)


        def multi_value(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.Multi_valueContext,0)


        def modifier(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.ModifierContext,0)


        def term_modifier(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.Term_modifierContext,0)


        def value(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.ValueContext,0)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_atom

        def enterRule(self, listener):
            if hasattr(listener, "enterAtom"):
                listener.enterAtom(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitAtom"):
                listener.exitAtom(self)




    def atom(self):

        localctx = ElasticsearchGrammarParser.AtomContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_atom)
        self._la = 0 # Token type
        try:
            self.state = 148
            la_ = self._interp.adaptivePredict(self._input,19,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 131
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.PLUS or _la==ElasticsearchGrammarParser.MINUS:
                    self.state = 130
                    self.modifier()


                self.state = 133
                self.field()
                self.state = 134
                self.multi_value()
                self.state = 136
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.CARAT or _la==ElasticsearchGrammarParser.TILDE:
                    self.state = 135
                    self.term_modifier()


                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 139
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.PLUS or _la==ElasticsearchGrammarParser.MINUS:
                    self.state = 138
                    self.modifier()


                self.state = 142
                la_ = self._interp.adaptivePredict(self._input,17,self._ctx)
                if la_ == 1:
                    self.state = 141
                    self.field()


                self.state = 144
                self.value()
                self.state = 146
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.CARAT or _la==ElasticsearchGrammarParser.TILDE:
                    self.state = 145
                    self.term_modifier()


                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class FieldContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.FieldContext, self).__init__(parent, invokingState)
            self.parser = parser

        def TERM_NORMAL(self):
            return self.getToken(ElasticsearchGrammarParser.TERM_NORMAL, 0)

        def COLON(self):
            return self.getToken(ElasticsearchGrammarParser.COLON, 0)

        def sep(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,0)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_field

        def enterRule(self, listener):
            if hasattr(listener, "enterField"):
                listener.enterField(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitField"):
                listener.exitField(self)




    def field(self):

        localctx = ElasticsearchGrammarParser.FieldContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_field)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 150
            self.match(ElasticsearchGrammarParser.TERM_NORMAL)
            self.state = 151
            self.match(ElasticsearchGrammarParser.COLON)
            self.state = 153
            _la = self._input.LA(1)
            if _la==ElasticsearchGrammarParser.WS:
                self.state = 152
                self.sep()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ValueContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.ValueContext, self).__init__(parent, invokingState)
            self.parser = parser

        def range_term(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.Range_termContext,0)


        def normal(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.NormalContext,0)


        def truncated(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.TruncatedContext,0)


        def quoted(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.QuotedContext,0)


        def quoted_truncated(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.Quoted_truncatedContext,0)


        def QMARK(self):
            return self.getToken(ElasticsearchGrammarParser.QMARK, 0)

        def anything(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.AnythingContext,0)


        def STAR(self):
            return self.getToken(ElasticsearchGrammarParser.STAR, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_value

        def enterRule(self, listener):
            if hasattr(listener, "enterValue"):
                listener.enterValue(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitValue"):
                listener.exitValue(self)




    def value(self):

        localctx = ElasticsearchGrammarParser.ValueContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_value)
        try:
            self.state = 163
            la_ = self._interp.adaptivePredict(self._input,21,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 155
                self.range_term()
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 156
                self.normal()
                pass

            elif la_ == 3:
                self.enterOuterAlt(localctx, 3)
                self.state = 157
                self.truncated()
                pass

            elif la_ == 4:
                self.enterOuterAlt(localctx, 4)
                self.state = 158
                self.quoted()
                pass

            elif la_ == 5:
                self.enterOuterAlt(localctx, 5)
                self.state = 159
                self.quoted_truncated()
                pass

            elif la_ == 6:
                self.enterOuterAlt(localctx, 6)
                self.state = 160
                self.match(ElasticsearchGrammarParser.QMARK)
                pass

            elif la_ == 7:
                self.enterOuterAlt(localctx, 7)
                self.state = 161
                self.anything()
                pass

            elif la_ == 8:
                self.enterOuterAlt(localctx, 8)
                self.state = 162
                self.match(ElasticsearchGrammarParser.STAR)
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class AnythingContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.AnythingContext, self).__init__(parent, invokingState)
            self.parser = parser

        def STAR(self, i=None):
            if i is None:
                return self.getTokens(ElasticsearchGrammarParser.STAR)
            else:
                return self.getToken(ElasticsearchGrammarParser.STAR, i)

        def COLON(self):
            return self.getToken(ElasticsearchGrammarParser.COLON, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_anything

        def enterRule(self, listener):
            if hasattr(listener, "enterAnything"):
                listener.enterAnything(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitAnything"):
                listener.exitAnything(self)




    def anything(self):

        localctx = ElasticsearchGrammarParser.AnythingContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_anything)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 165
            self.match(ElasticsearchGrammarParser.STAR)
            self.state = 166
            self.match(ElasticsearchGrammarParser.COLON)
            self.state = 167
            self.match(ElasticsearchGrammarParser.STAR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Two_sided_range_termContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.Two_sided_range_termContext, self).__init__(parent, invokingState)
            self.parser = parser
            self.start_type = None # Token
            self.a = None # Range_valueContext
            self.b = None # Range_valueContext
            self.end_type = None # Token

        def LBRACK(self):
            return self.getToken(ElasticsearchGrammarParser.LBRACK, 0)

        def LCURLY(self):
            return self.getToken(ElasticsearchGrammarParser.LCURLY, 0)

        def RBRACK(self):
            return self.getToken(ElasticsearchGrammarParser.RBRACK, 0)

        def RCURLY(self):
            return self.getToken(ElasticsearchGrammarParser.RCURLY, 0)

        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,i)


        def range_value(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.Range_valueContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.Range_valueContext,i)


        def TO(self):
            return self.getToken(ElasticsearchGrammarParser.TO, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_two_sided_range_term

        def enterRule(self, listener):
            if hasattr(listener, "enterTwo_sided_range_term"):
                listener.enterTwo_sided_range_term(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitTwo_sided_range_term"):
                listener.exitTwo_sided_range_term(self)




    def two_sided_range_term(self):

        localctx = ElasticsearchGrammarParser.Two_sided_range_termContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_two_sided_range_term)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 169
            localctx.start_type = self._input.LT(1)
            _la = self._input.LA(1)
            if not(_la==ElasticsearchGrammarParser.LBRACK or _la==ElasticsearchGrammarParser.LCURLY):
                localctx.start_type = self._errHandler.recoverInline(self)
            else:
                self.consume()
            self.state = 171
            _la = self._input.LA(1)
            if _la==ElasticsearchGrammarParser.WS:
                self.state = 170
                self.sep()


            self.state = 173
            localctx.a = self.range_value()
            self.state = 175
            la_ = self._interp.adaptivePredict(self._input,23,self._ctx)
            if la_ == 1:
                self.state = 174
                self.sep()


            self.state = 187
            _la = self._input.LA(1)
            if (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << ElasticsearchGrammarParser.STAR) | (1 << ElasticsearchGrammarParser.TO) | (1 << ElasticsearchGrammarParser.WS) | (1 << ElasticsearchGrammarParser.NUMBER) | (1 << ElasticsearchGrammarParser.DATE_TOKEN) | (1 << ElasticsearchGrammarParser.TERM_NORMAL) | (1 << ElasticsearchGrammarParser.TERM_TRUNCATED) | (1 << ElasticsearchGrammarParser.PHRASE) | (1 << ElasticsearchGrammarParser.PHRASE_ANYTHING))) != 0):
                self.state = 178
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.TO:
                    self.state = 177
                    self.match(ElasticsearchGrammarParser.TO)


                self.state = 181
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.WS:
                    self.state = 180
                    self.sep()


                self.state = 183
                localctx.b = self.range_value()
                self.state = 185
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.WS:
                    self.state = 184
                    self.sep()




            self.state = 189
            localctx.end_type = self._input.LT(1)
            _la = self._input.LA(1)
            if not(_la==ElasticsearchGrammarParser.RBRACK or _la==ElasticsearchGrammarParser.RCURLY):
                localctx.end_type = self._errHandler.recoverInline(self)
            else:
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Range_valueContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.Range_valueContext, self).__init__(parent, invokingState)
            self.parser = parser

        def truncated(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.TruncatedContext,0)


        def quoted(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.QuotedContext,0)


        def quoted_truncated(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.Quoted_truncatedContext,0)


        def date(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.DateContext,0)


        def normal(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.NormalContext,0)


        def STAR(self):
            return self.getToken(ElasticsearchGrammarParser.STAR, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_range_value

        def enterRule(self, listener):
            if hasattr(listener, "enterRange_value"):
                listener.enterRange_value(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitRange_value"):
                listener.exitRange_value(self)




    def range_value(self):

        localctx = ElasticsearchGrammarParser.Range_valueContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_range_value)
        try:
            self.state = 197
            token = self._input.LA(1)
            if token in [ElasticsearchGrammarParser.TERM_TRUNCATED]:
                self.enterOuterAlt(localctx, 1)
                self.state = 191
                self.truncated()

            elif token in [ElasticsearchGrammarParser.PHRASE]:
                self.enterOuterAlt(localctx, 2)
                self.state = 192
                self.quoted()

            elif token in [ElasticsearchGrammarParser.PHRASE_ANYTHING]:
                self.enterOuterAlt(localctx, 3)
                self.state = 193
                self.quoted_truncated()

            elif token in [ElasticsearchGrammarParser.DATE_TOKEN]:
                self.enterOuterAlt(localctx, 4)
                self.state = 194
                self.date()

            elif token in [ElasticsearchGrammarParser.NUMBER, ElasticsearchGrammarParser.TERM_NORMAL]:
                self.enterOuterAlt(localctx, 5)
                self.state = 195
                self.normal()

            elif token in [ElasticsearchGrammarParser.STAR]:
                self.enterOuterAlt(localctx, 6)
                self.state = 196
                self.match(ElasticsearchGrammarParser.STAR)

            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Multi_valueContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.Multi_valueContext, self).__init__(parent, invokingState)
            self.parser = parser

        def LPAREN(self):
            return self.getToken(ElasticsearchGrammarParser.LPAREN, 0)

        def clauseDefault(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.ClauseDefaultContext,0)


        def RPAREN(self):
            return self.getToken(ElasticsearchGrammarParser.RPAREN, 0)

        def sep(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,0)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_multi_value

        def enterRule(self, listener):
            if hasattr(listener, "enterMulti_value"):
                listener.enterMulti_value(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitMulti_value"):
                listener.exitMulti_value(self)




    def multi_value(self):

        localctx = ElasticsearchGrammarParser.Multi_valueContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_multi_value)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 199
            self.match(ElasticsearchGrammarParser.LPAREN)
            self.state = 200
            self.clauseDefault()
            self.state = 202
            _la = self._input.LA(1)
            if _la==ElasticsearchGrammarParser.WS:
                self.state = 201
                self.sep()


            self.state = 204
            self.match(ElasticsearchGrammarParser.RPAREN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class NormalContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.NormalContext, self).__init__(parent, invokingState)
            self.parser = parser

        def TERM_NORMAL(self):
            return self.getToken(ElasticsearchGrammarParser.TERM_NORMAL, 0)

        def NUMBER(self):
            return self.getToken(ElasticsearchGrammarParser.NUMBER, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_normal

        def enterRule(self, listener):
            if hasattr(listener, "enterNormal"):
                listener.enterNormal(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitNormal"):
                listener.exitNormal(self)




    def normal(self):

        localctx = ElasticsearchGrammarParser.NormalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_normal)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 206
            _la = self._input.LA(1)
            if not(_la==ElasticsearchGrammarParser.NUMBER or _la==ElasticsearchGrammarParser.TERM_NORMAL):
                self._errHandler.recoverInline(self)
            else:
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class TruncatedContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.TruncatedContext, self).__init__(parent, invokingState)
            self.parser = parser

        def TERM_TRUNCATED(self):
            return self.getToken(ElasticsearchGrammarParser.TERM_TRUNCATED, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_truncated

        def enterRule(self, listener):
            if hasattr(listener, "enterTruncated"):
                listener.enterTruncated(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitTruncated"):
                listener.exitTruncated(self)




    def truncated(self):

        localctx = ElasticsearchGrammarParser.TruncatedContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_truncated)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 208
            self.match(ElasticsearchGrammarParser.TERM_TRUNCATED)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Quoted_truncatedContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.Quoted_truncatedContext, self).__init__(parent, invokingState)
            self.parser = parser

        def PHRASE_ANYTHING(self):
            return self.getToken(ElasticsearchGrammarParser.PHRASE_ANYTHING, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_quoted_truncated

        def enterRule(self, listener):
            if hasattr(listener, "enterQuoted_truncated"):
                listener.enterQuoted_truncated(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitQuoted_truncated"):
                listener.exitQuoted_truncated(self)




    def quoted_truncated(self):

        localctx = ElasticsearchGrammarParser.Quoted_truncatedContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_quoted_truncated)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 210
            self.match(ElasticsearchGrammarParser.PHRASE_ANYTHING)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class QuotedContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.QuotedContext, self).__init__(parent, invokingState)
            self.parser = parser

        def PHRASE(self):
            return self.getToken(ElasticsearchGrammarParser.PHRASE, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_quoted

        def enterRule(self, listener):
            if hasattr(listener, "enterQuoted"):
                listener.enterQuoted(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitQuoted"):
                listener.exitQuoted(self)




    def quoted(self):

        localctx = ElasticsearchGrammarParser.QuotedContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_quoted)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 212
            self.match(ElasticsearchGrammarParser.PHRASE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ModifierContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.ModifierContext, self).__init__(parent, invokingState)
            self.parser = parser

        def PLUS(self):
            return self.getToken(ElasticsearchGrammarParser.PLUS, 0)

        def MINUS(self):
            return self.getToken(ElasticsearchGrammarParser.MINUS, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_modifier

        def enterRule(self, listener):
            if hasattr(listener, "enterModifier"):
                listener.enterModifier(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitModifier"):
                listener.exitModifier(self)




    def modifier(self):

        localctx = ElasticsearchGrammarParser.ModifierContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_modifier)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 214
            _la = self._input.LA(1)
            if not(_la==ElasticsearchGrammarParser.PLUS or _la==ElasticsearchGrammarParser.MINUS):
                self._errHandler.recoverInline(self)
            else:
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Term_modifierContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.Term_modifierContext, self).__init__(parent, invokingState)
            self.parser = parser

        def boost(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.BoostContext,0)


        def fuzzy(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.FuzzyContext,0)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_term_modifier

        def enterRule(self, listener):
            if hasattr(listener, "enterTerm_modifier"):
                listener.enterTerm_modifier(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitTerm_modifier"):
                listener.exitTerm_modifier(self)




    def term_modifier(self):

        localctx = ElasticsearchGrammarParser.Term_modifierContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_term_modifier)
        self._la = 0 # Token type
        try:
            self.state = 224
            token = self._input.LA(1)
            if token in [ElasticsearchGrammarParser.CARAT]:
                self.enterOuterAlt(localctx, 1)
                self.state = 216
                self.boost()
                self.state = 218
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.TILDE:
                    self.state = 217
                    self.fuzzy()



            elif token in [ElasticsearchGrammarParser.TILDE]:
                self.enterOuterAlt(localctx, 2)
                self.state = 220
                self.fuzzy()
                self.state = 222
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.CARAT:
                    self.state = 221
                    self.boost()



            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class BoostContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.BoostContext, self).__init__(parent, invokingState)
            self.parser = parser

        def CARAT(self):
            return self.getToken(ElasticsearchGrammarParser.CARAT, 0)

        def NUMBER(self):
            return self.getToken(ElasticsearchGrammarParser.NUMBER, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_boost

        def enterRule(self, listener):
            if hasattr(listener, "enterBoost"):
                listener.enterBoost(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitBoost"):
                listener.exitBoost(self)




    def boost(self):

        localctx = ElasticsearchGrammarParser.BoostContext(self, self._ctx, self.state)
        self.enterRule(localctx, 42, self.RULE_boost)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 226
            self.match(ElasticsearchGrammarParser.CARAT)
            self.state = 228
            la_ = self._interp.adaptivePredict(self._input,33,self._ctx)
            if la_ == 1:
                self.state = 227
                self.match(ElasticsearchGrammarParser.NUMBER)


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class FuzzyContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.FuzzyContext, self).__init__(parent, invokingState)
            self.parser = parser

        def TILDE(self):
            return self.getToken(ElasticsearchGrammarParser.TILDE, 0)

        def NUMBER(self):
            return self.getToken(ElasticsearchGrammarParser.NUMBER, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_fuzzy

        def enterRule(self, listener):
            if hasattr(listener, "enterFuzzy"):
                listener.enterFuzzy(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitFuzzy"):
                listener.exitFuzzy(self)




    def fuzzy(self):

        localctx = ElasticsearchGrammarParser.FuzzyContext(self, self._ctx, self.state)
        self.enterRule(localctx, 44, self.RULE_fuzzy)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 230
            self.match(ElasticsearchGrammarParser.TILDE)
            self.state = 232
            la_ = self._interp.adaptivePredict(self._input,34,self._ctx)
            if la_ == 1:
                self.state = 231
                self.match(ElasticsearchGrammarParser.NUMBER)


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Not_Context(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.Not_Context, self).__init__(parent, invokingState)
            self.parser = parser

        def AND(self):
            return self.getToken(ElasticsearchGrammarParser.AND, 0)

        def NOT(self):
            return self.getToken(ElasticsearchGrammarParser.NOT, 0)

        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(ElasticsearchGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,i)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_not_

        def enterRule(self, listener):
            if hasattr(listener, "enterNot_"):
                listener.enterNot_(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitNot_"):
                listener.exitNot_(self)




    def not_(self):

        localctx = ElasticsearchGrammarParser.Not_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 46, self.RULE_not_)
        self._la = 0 # Token type
        try:
            self.state = 246
            la_ = self._interp.adaptivePredict(self._input,38,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 235
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.WS:
                    self.state = 234
                    self.sep()


                self.state = 237
                self.match(ElasticsearchGrammarParser.AND)
                self.state = 239
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.WS:
                    self.state = 238
                    self.sep()


                self.state = 241
                self.match(ElasticsearchGrammarParser.NOT)
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 243
                _la = self._input.LA(1)
                if _la==ElasticsearchGrammarParser.WS:
                    self.state = 242
                    self.sep()


                self.state = 245
                self.match(ElasticsearchGrammarParser.NOT)
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class And_Context(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.And_Context, self).__init__(parent, invokingState)
            self.parser = parser

        def AND(self):
            return self.getToken(ElasticsearchGrammarParser.AND, 0)

        def sep(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,0)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_and_

        def enterRule(self, listener):
            if hasattr(listener, "enterAnd_"):
                listener.enterAnd_(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitAnd_"):
                listener.exitAnd_(self)




    def and_(self):

        localctx = ElasticsearchGrammarParser.And_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 48, self.RULE_and_)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 249
            _la = self._input.LA(1)
            if _la==ElasticsearchGrammarParser.WS:
                self.state = 248
                self.sep()


            self.state = 251
            self.match(ElasticsearchGrammarParser.AND)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Or_Context(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.Or_Context, self).__init__(parent, invokingState)
            self.parser = parser

        def OR(self):
            return self.getToken(ElasticsearchGrammarParser.OR, 0)

        def sep(self):
            return self.getTypedRuleContext(ElasticsearchGrammarParser.SepContext,0)


        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_or_

        def enterRule(self, listener):
            if hasattr(listener, "enterOr_"):
                listener.enterOr_(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitOr_"):
                listener.exitOr_(self)




    def or_(self):

        localctx = ElasticsearchGrammarParser.Or_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 50, self.RULE_or_)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 254
            _la = self._input.LA(1)
            if _la==ElasticsearchGrammarParser.WS:
                self.state = 253
                self.sep()


            self.state = 256
            self.match(ElasticsearchGrammarParser.OR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class DateContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.DateContext, self).__init__(parent, invokingState)
            self.parser = parser

        def DATE_TOKEN(self):
            return self.getToken(ElasticsearchGrammarParser.DATE_TOKEN, 0)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_date

        def enterRule(self, listener):
            if hasattr(listener, "enterDate"):
                listener.enterDate(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitDate"):
                listener.exitDate(self)




    def date(self):

        localctx = ElasticsearchGrammarParser.DateContext(self, self._ctx, self.state)
        self.enterRule(localctx, 52, self.RULE_date)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 258
            self.match(ElasticsearchGrammarParser.DATE_TOKEN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class SepContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(ElasticsearchGrammarParser.SepContext, self).__init__(parent, invokingState)
            self.parser = parser

        def WS(self, i=None):
            if i is None:
                return self.getTokens(ElasticsearchGrammarParser.WS)
            else:
                return self.getToken(ElasticsearchGrammarParser.WS, i)

        def getRuleIndex(self):
            return ElasticsearchGrammarParser.RULE_sep

        def enterRule(self, listener):
            if hasattr(listener, "enterSep"):
                listener.enterSep(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitSep"):
                listener.exitSep(self)




    def sep(self):

        localctx = ElasticsearchGrammarParser.SepContext(self, self._ctx, self.state)
        self.enterRule(localctx, 54, self.RULE_sep)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 261 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 260
                    self.match(ElasticsearchGrammarParser.WS)

                else:
                    raise NoViableAltException(self)
                self.state = 263 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,41,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





