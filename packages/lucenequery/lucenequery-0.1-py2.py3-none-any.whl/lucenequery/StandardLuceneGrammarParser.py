# Generated from StandardLuceneGrammar.g4 by ANTLR 4.5.1
# encoding: utf-8
from __future__ import print_function
from antlr4 import *
from io import StringIO

def serializedATN():
    with StringIO() as buf:
        buf.write(u"\3\u0430\ud6d1\u8206\uad2d\u4417\uaef1\u8d80\uaadd\3")
        buf.write(u",\u0105\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t")
        buf.write(u"\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r")
        buf.write(u"\4\16\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4")
        buf.write(u"\23\t\23\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30")
        buf.write(u"\t\30\4\31\t\31\4\32\t\32\4\33\t\33\4\34\t\34\3\2\5\2")
        buf.write(u":\n\2\3\2\3\2\5\2>\n\2\3\2\3\2\3\3\3\3\5\3D\n\3\3\3\7")
        buf.write(u"\3G\n\3\f\3\16\3J\13\3\3\4\3\4\3\4\3\4\7\4P\n\4\f\4\16")
        buf.write(u"\4S\13\4\3\5\3\5\3\5\3\5\7\5Y\n\5\f\5\16\5\\\13\5\3\6")
        buf.write(u"\3\6\3\6\3\6\7\6b\n\6\f\6\16\6e\13\6\3\7\5\7h\n\7\3\7")
        buf.write(u"\5\7k\n\7\3\7\3\7\3\7\5\7p\n\7\3\7\3\7\5\7t\n\7\3\7\5")
        buf.write(u"\7w\n\7\3\7\5\7z\n\7\3\b\5\b}\n\b\3\b\3\b\3\b\5\b\u0082")
        buf.write(u"\n\b\3\b\5\b\u0085\n\b\3\b\5\b\u0088\n\b\3\b\3\b\5\b")
        buf.write(u"\u008c\n\b\5\b\u008e\n\b\3\t\3\t\3\t\5\t\u0093\n\t\3")
        buf.write(u"\n\3\n\3\n\3\n\3\n\3\n\3\n\3\n\5\n\u009d\n\n\3\13\3\13")
        buf.write(u"\3\13\3\13\3\f\3\f\5\f\u00a5\n\f\3\f\3\f\5\f\u00a9\n")
        buf.write(u"\f\3\f\5\f\u00ac\n\f\3\f\5\f\u00af\n\f\3\f\3\f\5\f\u00b3")
        buf.write(u"\n\f\5\f\u00b5\n\f\3\f\3\f\3\r\3\r\3\16\3\16\3\16\3\16")
        buf.write(u"\3\16\3\16\5\16\u00c1\n\16\3\17\3\17\3\17\5\17\u00c6")
        buf.write(u"\n\17\3\17\3\17\3\20\3\20\3\21\3\21\3\22\3\22\3\23\3")
        buf.write(u"\23\3\24\3\24\3\25\3\25\5\25\u00d6\n\25\3\25\3\25\5\25")
        buf.write(u"\u00da\n\25\5\25\u00dc\n\25\3\26\3\26\5\26\u00e0\n\26")
        buf.write(u"\3\27\3\27\5\27\u00e4\n\27\3\30\5\30\u00e7\n\30\3\30")
        buf.write(u"\3\30\5\30\u00eb\n\30\3\30\3\30\5\30\u00ef\n\30\3\30")
        buf.write(u"\5\30\u00f2\n\30\3\31\5\31\u00f5\n\31\3\31\3\31\3\32")
        buf.write(u"\5\32\u00fa\n\32\3\32\3\32\3\33\3\33\3\34\6\34\u0101")
        buf.write(u"\n\34\r\34\16\34\u0102\3\34\2\2\35\2\4\6\b\n\f\16\20")
        buf.write(u"\22\24\26\30\32\34\36 \"$&(*,.\60\62\64\66\2\6\4\2\5")
        buf.write(u"\5\f\f\4\2\6\6\r\r\4\2\27\27\31\31\3\2\b\t\u011c\29\3")
        buf.write(u"\2\2\2\4A\3\2\2\2\6K\3\2\2\2\bT\3\2\2\2\n]\3\2\2\2\f")
        buf.write(u"y\3\2\2\2\16\u008d\3\2\2\2\20\u008f\3\2\2\2\22\u009c")
        buf.write(u"\3\2\2\2\24\u009e\3\2\2\2\26\u00a2\3\2\2\2\30\u00b8\3")
        buf.write(u"\2\2\2\32\u00c0\3\2\2\2\34\u00c2\3\2\2\2\36\u00c9\3\2")
        buf.write(u"\2\2 \u00cb\3\2\2\2\"\u00cd\3\2\2\2$\u00cf\3\2\2\2&\u00d1")
        buf.write(u"\3\2\2\2(\u00db\3\2\2\2*\u00dd\3\2\2\2,\u00e1\3\2\2\2")
        buf.write(u".\u00f1\3\2\2\2\60\u00f4\3\2\2\2\62\u00f9\3\2\2\2\64")
        buf.write(u"\u00fd\3\2\2\2\66\u0100\3\2\2\28:\5\66\34\298\3\2\2\2")
        buf.write(u"9:\3\2\2\2:;\3\2\2\2;=\5\4\3\2<>\5\66\34\2=<\3\2\2\2")
        buf.write(u"=>\3\2\2\2>?\3\2\2\2?@\7\2\2\3@\3\3\2\2\2AH\5\6\4\2B")
        buf.write(u"D\5\66\34\2CB\3\2\2\2CD\3\2\2\2DE\3\2\2\2EG\5\6\4\2F")
        buf.write(u"C\3\2\2\2GJ\3\2\2\2HF\3\2\2\2HI\3\2\2\2I\5\3\2\2\2JH")
        buf.write(u"\3\2\2\2KQ\5\b\5\2LM\5\62\32\2MN\5\b\5\2NP\3\2\2\2OL")
        buf.write(u"\3\2\2\2PS\3\2\2\2QO\3\2\2\2QR\3\2\2\2R\7\3\2\2\2SQ\3")
        buf.write(u"\2\2\2TZ\5\n\6\2UV\5\60\31\2VW\5\n\6\2WY\3\2\2\2XU\3")
        buf.write(u"\2\2\2Y\\\3\2\2\2ZX\3\2\2\2Z[\3\2\2\2[\t\3\2\2\2\\Z\3")
        buf.write(u"\2\2\2]c\5\f\7\2^_\5.\30\2_`\5\f\7\2`b\3\2\2\2a^\3\2")
        buf.write(u"\2\2be\3\2\2\2ca\3\2\2\2cd\3\2\2\2d\13\3\2\2\2ec\3\2")
        buf.write(u"\2\2fh\5\66\34\2gf\3\2\2\2gh\3\2\2\2hj\3\2\2\2ik\5&\24")
        buf.write(u"\2ji\3\2\2\2jk\3\2\2\2kl\3\2\2\2lm\7\3\2\2mo\5\4\3\2")
        buf.write(u"np\5\66\34\2on\3\2\2\2op\3\2\2\2pq\3\2\2\2qs\7\4\2\2")
        buf.write(u"rt\5(\25\2sr\3\2\2\2st\3\2\2\2tz\3\2\2\2uw\5\66\34\2")
        buf.write(u"vu\3\2\2\2vw\3\2\2\2wx\3\2\2\2xz\5\16\b\2yg\3\2\2\2y")
        buf.write(u"v\3\2\2\2z\r\3\2\2\2{}\5&\24\2|{\3\2\2\2|}\3\2\2\2}~")
        buf.write(u"\3\2\2\2~\177\5\20\t\2\177\u0081\5\34\17\2\u0080\u0082")
        buf.write(u"\5(\25\2\u0081\u0080\3\2\2\2\u0081\u0082\3\2\2\2\u0082")
        buf.write(u"\u008e\3\2\2\2\u0083\u0085\5&\24\2\u0084\u0083\3\2\2")
        buf.write(u"\2\u0084\u0085\3\2\2\2\u0085\u0087\3\2\2\2\u0086\u0088")
        buf.write(u"\5\20\t\2\u0087\u0086\3\2\2\2\u0087\u0088\3\2\2\2\u0088")
        buf.write(u"\u0089\3\2\2\2\u0089\u008b\5\22\n\2\u008a\u008c\5(\25")
        buf.write(u"\2\u008b\u008a\3\2\2\2\u008b\u008c\3\2\2\2\u008c\u008e")
        buf.write(u"\3\2\2\2\u008d|\3\2\2\2\u008d\u0084\3\2\2\2\u008e\17")
        buf.write(u"\3\2\2\2\u008f\u0090\7\31\2\2\u0090\u0092\7\7\2\2\u0091")
        buf.write(u"\u0093\5\66\34\2\u0092\u0091\3\2\2\2\u0092\u0093\3\2")
        buf.write(u"\2\2\u0093\21\3\2\2\2\u0094\u009d\5\30\r\2\u0095\u009d")
        buf.write(u"\5\36\20\2\u0096\u009d\5 \21\2\u0097\u009d\5$\23\2\u0098")
        buf.write(u"\u009d\5\"\22\2\u0099\u009d\7\13\2\2\u009a\u009d\5\24")
        buf.write(u"\13\2\u009b\u009d\7\n\2\2\u009c\u0094\3\2\2\2\u009c\u0095")
        buf.write(u"\3\2\2\2\u009c\u0096\3\2\2\2\u009c\u0097\3\2\2\2\u009c")
        buf.write(u"\u0098\3\2\2\2\u009c\u0099\3\2\2\2\u009c\u009a\3\2\2")
        buf.write(u"\2\u009c\u009b\3\2\2\2\u009d\23\3\2\2\2\u009e\u009f\7")
        buf.write(u"\n\2\2\u009f\u00a0\7\7\2\2\u00a0\u00a1\7\n\2\2\u00a1")
        buf.write(u"\25\3\2\2\2\u00a2\u00a4\t\2\2\2\u00a3\u00a5\5\66\34\2")
        buf.write(u"\u00a4\u00a3\3\2\2\2\u00a4\u00a5\3\2\2\2\u00a5\u00a6")
        buf.write(u"\3\2\2\2\u00a6\u00a8\5\32\16\2\u00a7\u00a9\5\66\34\2")
        buf.write(u"\u00a8\u00a7\3\2\2\2\u00a8\u00a9\3\2\2\2\u00a9\u00b4")
        buf.write(u"\3\2\2\2\u00aa\u00ac\7\22\2\2\u00ab\u00aa\3\2\2\2\u00ab")
        buf.write(u"\u00ac\3\2\2\2\u00ac\u00ae\3\2\2\2\u00ad\u00af\5\66\34")
        buf.write(u"\2\u00ae\u00ad\3\2\2\2\u00ae\u00af\3\2\2\2\u00af\u00b0")
        buf.write(u"\3\2\2\2\u00b0\u00b2\5\32\16\2\u00b1\u00b3\5\66\34\2")
        buf.write(u"\u00b2\u00b1\3\2\2\2\u00b2\u00b3\3\2\2\2\u00b3\u00b5")
        buf.write(u"\3\2\2\2\u00b4\u00ab\3\2\2\2\u00b4\u00b5\3\2\2\2\u00b5")
        buf.write(u"\u00b6\3\2\2\2\u00b6\u00b7\t\3\2\2\u00b7\27\3\2\2\2\u00b8")
        buf.write(u"\u00b9\5\26\f\2\u00b9\31\3\2\2\2\u00ba\u00c1\5 \21\2")
        buf.write(u"\u00bb\u00c1\5$\23\2\u00bc\u00c1\5\"\22\2\u00bd\u00c1")
        buf.write(u"\5\64\33\2\u00be\u00c1\5\36\20\2\u00bf\u00c1\7\n\2\2")
        buf.write(u"\u00c0\u00ba\3\2\2\2\u00c0\u00bb\3\2\2\2\u00c0\u00bc")
        buf.write(u"\3\2\2\2\u00c0\u00bd\3\2\2\2\u00c0\u00be\3\2\2\2\u00c0")
        buf.write(u"\u00bf\3\2\2\2\u00c1\33\3\2\2\2\u00c2\u00c3\7\3\2\2\u00c3")
        buf.write(u"\u00c5\5\4\3\2\u00c4\u00c6\5\66\34\2\u00c5\u00c4\3\2")
        buf.write(u"\2\2\u00c5\u00c6\3\2\2\2\u00c6\u00c7\3\2\2\2\u00c7\u00c8")
        buf.write(u"\7\4\2\2\u00c8\35\3\2\2\2\u00c9\u00ca\t\4\2\2\u00ca\37")
        buf.write(u"\3\2\2\2\u00cb\u00cc\7\32\2\2\u00cc!\3\2\2\2\u00cd\u00ce")
        buf.write(u"\7\34\2\2\u00ce#\3\2\2\2\u00cf\u00d0\7\33\2\2\u00d0%")
        buf.write(u"\3\2\2\2\u00d1\u00d2\t\5\2\2\u00d2\'\3\2\2\2\u00d3\u00d5")
        buf.write(u"\5*\26\2\u00d4\u00d6\5,\27\2\u00d5\u00d4\3\2\2\2\u00d5")
        buf.write(u"\u00d6\3\2\2\2\u00d6\u00dc\3\2\2\2\u00d7\u00d9\5,\27")
        buf.write(u"\2\u00d8\u00da\5*\26\2\u00d9\u00d8\3\2\2\2\u00d9\u00da")
        buf.write(u"\3\2\2\2\u00da\u00dc\3\2\2\2\u00db\u00d3\3\2\2\2\u00db")
        buf.write(u"\u00d7\3\2\2\2\u00dc)\3\2\2\2\u00dd\u00df\7\16\2\2\u00de")
        buf.write(u"\u00e0\7\27\2\2\u00df\u00de\3\2\2\2\u00df\u00e0\3\2\2")
        buf.write(u"\2\u00e0+\3\2\2\2\u00e1\u00e3\7\17\2\2\u00e2\u00e4\7")
        buf.write(u"\27\2\2\u00e3\u00e2\3\2\2\2\u00e3\u00e4\3\2\2\2\u00e4")
        buf.write(u"-\3\2\2\2\u00e5\u00e7\5\66\34\2\u00e6\u00e5\3\2\2\2\u00e6")
        buf.write(u"\u00e7\3\2\2\2\u00e7\u00e8\3\2\2\2\u00e8\u00ea\7\23\2")
        buf.write(u"\2\u00e9\u00eb\5\66\34\2\u00ea\u00e9\3\2\2\2\u00ea\u00eb")
        buf.write(u"\3\2\2\2\u00eb\u00ec\3\2\2\2\u00ec\u00f2\7\25\2\2\u00ed")
        buf.write(u"\u00ef\5\66\34\2\u00ee\u00ed\3\2\2\2\u00ee\u00ef\3\2")
        buf.write(u"\2\2\u00ef\u00f0\3\2\2\2\u00f0\u00f2\7\25\2\2\u00f1\u00e6")
        buf.write(u"\3\2\2\2\u00f1\u00ee\3\2\2\2\u00f2/\3\2\2\2\u00f3\u00f5")
        buf.write(u"\5\66\34\2\u00f4\u00f3\3\2\2\2\u00f4\u00f5\3\2\2\2\u00f5")
        buf.write(u"\u00f6\3\2\2\2\u00f6\u00f7\7\23\2\2\u00f7\61\3\2\2\2")
        buf.write(u"\u00f8\u00fa\5\66\34\2\u00f9\u00f8\3\2\2\2\u00f9\u00fa")
        buf.write(u"\3\2\2\2\u00fa\u00fb\3\2\2\2\u00fb\u00fc\7\24\2\2\u00fc")
        buf.write(u"\63\3\2\2\2\u00fd\u00fe\7\30\2\2\u00fe\65\3\2\2\2\u00ff")
        buf.write(u"\u0101\7\26\2\2\u0100\u00ff\3\2\2\2\u0101\u0102\3\2\2")
        buf.write(u"\2\u0102\u0100\3\2\2\2\u0102\u0103\3\2\2\2\u0103\67\3")
        buf.write(u"\2\2\2+9=CHQZcgjosvy|\u0081\u0084\u0087\u008b\u008d\u0092")
        buf.write(u"\u009c\u00a4\u00a8\u00ab\u00ae\u00b2\u00b4\u00c0\u00c5")
        buf.write(u"\u00d5\u00d9\u00db\u00df\u00e3\u00e6\u00ea\u00ee\u00f1")
        buf.write(u"\u00f4\u00f9\u0102")
        return buf.getvalue()


class StandardLuceneGrammarParser ( Parser ):

    grammarFileName = "StandardLuceneGrammar.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ u"<INVALID>", u"'('", u"')'", u"'['", u"']'", u"':'", 
                     u"'+'", u"<INVALID>", u"'*'", u"<INVALID>", u"'{'", 
                     u"'}'", u"<INVALID>", u"<INVALID>", u"'\"'", u"'''", 
                     u"'TO'" ]

    symbolicNames = [ u"<INVALID>", u"LPAREN", u"RPAREN", u"LBRACK", u"RBRACK", 
                      u"COLON", u"PLUS", u"MINUS", u"STAR", u"QMARK", u"LCURLY", 
                      u"RCURLY", u"CARAT", u"TILDE", u"DQUOTE", u"SQUOTE", 
                      u"TO", u"AND", u"OR", u"NOT", u"WS", u"NUMBER", u"DATE_TOKEN", 
                      u"TERM_NORMAL", u"TERM_TRUNCATED", u"PHRASE", u"PHRASE_ANYTHING", 
                      u"OPERATOR", u"ATOM", u"MODIFIER", u"TMODIFIER", u"CLAUSE", 
                      u"FIELD", u"FUZZY", u"BOOST", u"QNORMAL", u"QPHRASE", 
                      u"QPHRASETRUNC", u"QTRUNCATED", u"QRANGEIN", u"QRANGEEX", 
                      u"QANYTHING", u"QDATE" ]

    RULE_mainQ = 0
    RULE_clauseDefault = 1
    RULE_clauseOr = 2
    RULE_clauseAnd = 3
    RULE_clauseNot = 4
    RULE_clauseBasic = 5
    RULE_atom = 6
    RULE_field = 7
    RULE_value = 8
    RULE_anything = 9
    RULE_two_sided_range_term = 10
    RULE_range_term = 11
    RULE_range_value = 12
    RULE_multi_value = 13
    RULE_normal = 14
    RULE_truncated = 15
    RULE_quoted_truncated = 16
    RULE_quoted = 17
    RULE_modifier = 18
    RULE_term_modifier = 19
    RULE_boost = 20
    RULE_fuzzy = 21
    RULE_not_ = 22
    RULE_and_ = 23
    RULE_or_ = 24
    RULE_date = 25
    RULE_sep = 26

    ruleNames =  [ u"mainQ", u"clauseDefault", u"clauseOr", u"clauseAnd", 
                   u"clauseNot", u"clauseBasic", u"atom", u"field", u"value", 
                   u"anything", u"two_sided_range_term", u"range_term", 
                   u"range_value", u"multi_value", u"normal", u"truncated", 
                   u"quoted_truncated", u"quoted", u"modifier", u"term_modifier", 
                   u"boost", u"fuzzy", u"not_", u"and_", u"or_", u"date", 
                   u"sep" ]

    EOF = Token.EOF
    LPAREN=1
    RPAREN=2
    LBRACK=3
    RBRACK=4
    COLON=5
    PLUS=6
    MINUS=7
    STAR=8
    QMARK=9
    LCURLY=10
    RCURLY=11
    CARAT=12
    TILDE=13
    DQUOTE=14
    SQUOTE=15
    TO=16
    AND=17
    OR=18
    NOT=19
    WS=20
    NUMBER=21
    DATE_TOKEN=22
    TERM_NORMAL=23
    TERM_TRUNCATED=24
    PHRASE=25
    PHRASE_ANYTHING=26
    OPERATOR=27
    ATOM=28
    MODIFIER=29
    TMODIFIER=30
    CLAUSE=31
    FIELD=32
    FUZZY=33
    BOOST=34
    QNORMAL=35
    QPHRASE=36
    QPHRASETRUNC=37
    QTRUNCATED=38
    QRANGEIN=39
    QRANGEEX=40
    QANYTHING=41
    QDATE=42

    def __init__(self, input):
        super(StandardLuceneGrammarParser, self).__init__(input)
        self.checkVersion("4.5.1")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None



    class MainQContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.MainQContext, self).__init__(parent, invokingState)
            self.parser = parser
            self.clause = None # ClauseDefaultContext

        def EOF(self):
            return self.getToken(StandardLuceneGrammarParser.EOF, 0)

        def clauseDefault(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.ClauseDefaultContext,0)


        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,i)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_mainQ

        def enterRule(self, listener):
            if hasattr(listener, "enterMainQ"):
                listener.enterMainQ(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitMainQ"):
                listener.exitMainQ(self)




    def mainQ(self):

        localctx = StandardLuceneGrammarParser.MainQContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_mainQ)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 55
            la_ = self._interp.adaptivePredict(self._input,0,self._ctx)
            if la_ == 1:
                self.state = 54
                self.sep()


            self.state = 57
            localctx.clause = self.clauseDefault()
            self.state = 59
            _la = self._input.LA(1)
            if _la==StandardLuceneGrammarParser.WS:
                self.state = 58
                self.sep()


            self.state = 61
            self.match(StandardLuceneGrammarParser.EOF)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseDefaultContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.ClauseDefaultContext, self).__init__(parent, invokingState)
            self.parser = parser

        def clauseOr(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.ClauseOrContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.ClauseOrContext,i)


        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,i)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_clauseDefault

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseDefault"):
                listener.enterClauseDefault(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseDefault"):
                listener.exitClauseDefault(self)




    def clauseDefault(self):

        localctx = StandardLuceneGrammarParser.ClauseDefaultContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_clauseDefault)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 63
            self.clauseOr()
            self.state = 70
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,3,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 65
                    la_ = self._interp.adaptivePredict(self._input,2,self._ctx)
                    if la_ == 1:
                        self.state = 64
                        self.sep()


                    self.state = 67
                    self.clauseOr() 
                self.state = 72
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,3,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseOrContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.ClauseOrContext, self).__init__(parent, invokingState)
            self.parser = parser

        def clauseAnd(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.ClauseAndContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.ClauseAndContext,i)


        def or_(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.Or_Context)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.Or_Context,i)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_clauseOr

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseOr"):
                listener.enterClauseOr(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseOr"):
                listener.exitClauseOr(self)




    def clauseOr(self):

        localctx = StandardLuceneGrammarParser.ClauseOrContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_clauseOr)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 73
            self.clauseAnd()
            self.state = 79
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,4,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 74
                    self.or_()
                    self.state = 75
                    self.clauseAnd() 
                self.state = 81
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,4,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseAndContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.ClauseAndContext, self).__init__(parent, invokingState)
            self.parser = parser

        def clauseNot(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.ClauseNotContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.ClauseNotContext,i)


        def and_(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.And_Context)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.And_Context,i)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_clauseAnd

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseAnd"):
                listener.enterClauseAnd(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseAnd"):
                listener.exitClauseAnd(self)




    def clauseAnd(self):

        localctx = StandardLuceneGrammarParser.ClauseAndContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_clauseAnd)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 82
            self.clauseNot()
            self.state = 88
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,5,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 83
                    self.and_()
                    self.state = 84
                    self.clauseNot() 
                self.state = 90
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,5,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseNotContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.ClauseNotContext, self).__init__(parent, invokingState)
            self.parser = parser

        def clauseBasic(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.ClauseBasicContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.ClauseBasicContext,i)


        def not_(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.Not_Context)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.Not_Context,i)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_clauseNot

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseNot"):
                listener.enterClauseNot(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseNot"):
                listener.exitClauseNot(self)




    def clauseNot(self):

        localctx = StandardLuceneGrammarParser.ClauseNotContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_clauseNot)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 91
            self.clauseBasic()
            self.state = 97
            self._errHandler.sync(self)
            _alt = self._interp.adaptivePredict(self._input,6,self._ctx)
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt==1:
                    self.state = 92
                    self.not_()
                    self.state = 93
                    self.clauseBasic() 
                self.state = 99
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,6,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClauseBasicContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.ClauseBasicContext, self).__init__(parent, invokingState)
            self.parser = parser

        def LPAREN(self):
            return self.getToken(StandardLuceneGrammarParser.LPAREN, 0)

        def clauseDefault(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.ClauseDefaultContext,0)


        def RPAREN(self):
            return self.getToken(StandardLuceneGrammarParser.RPAREN, 0)

        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,i)


        def modifier(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.ModifierContext,0)


        def term_modifier(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.Term_modifierContext,0)


        def atom(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.AtomContext,0)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_clauseBasic

        def enterRule(self, listener):
            if hasattr(listener, "enterClauseBasic"):
                listener.enterClauseBasic(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitClauseBasic"):
                listener.exitClauseBasic(self)




    def clauseBasic(self):

        localctx = StandardLuceneGrammarParser.ClauseBasicContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_clauseBasic)
        self._la = 0 # Token type
        try:
            self.state = 119
            la_ = self._interp.adaptivePredict(self._input,12,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 101
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.WS:
                    self.state = 100
                    self.sep()


                self.state = 104
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.PLUS or _la==StandardLuceneGrammarParser.MINUS:
                    self.state = 103
                    self.modifier()


                self.state = 106
                self.match(StandardLuceneGrammarParser.LPAREN)
                self.state = 107
                self.clauseDefault()
                self.state = 109
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.WS:
                    self.state = 108
                    self.sep()


                self.state = 111
                self.match(StandardLuceneGrammarParser.RPAREN)
                self.state = 113
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.CARAT or _la==StandardLuceneGrammarParser.TILDE:
                    self.state = 112
                    self.term_modifier()


                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 116
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.WS:
                    self.state = 115
                    self.sep()


                self.state = 118
                self.atom()
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class AtomContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.AtomContext, self).__init__(parent, invokingState)
            self.parser = parser

        def field(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.FieldContext,0)


        def multi_value(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.Multi_valueContext,0)


        def modifier(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.ModifierContext,0)


        def term_modifier(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.Term_modifierContext,0)


        def value(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.ValueContext,0)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_atom

        def enterRule(self, listener):
            if hasattr(listener, "enterAtom"):
                listener.enterAtom(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitAtom"):
                listener.exitAtom(self)




    def atom(self):

        localctx = StandardLuceneGrammarParser.AtomContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_atom)
        self._la = 0 # Token type
        try:
            self.state = 139
            la_ = self._interp.adaptivePredict(self._input,18,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 122
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.PLUS or _la==StandardLuceneGrammarParser.MINUS:
                    self.state = 121
                    self.modifier()


                self.state = 124
                self.field()
                self.state = 125
                self.multi_value()
                self.state = 127
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.CARAT or _la==StandardLuceneGrammarParser.TILDE:
                    self.state = 126
                    self.term_modifier()


                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 130
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.PLUS or _la==StandardLuceneGrammarParser.MINUS:
                    self.state = 129
                    self.modifier()


                self.state = 133
                la_ = self._interp.adaptivePredict(self._input,16,self._ctx)
                if la_ == 1:
                    self.state = 132
                    self.field()


                self.state = 135
                self.value()
                self.state = 137
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.CARAT or _la==StandardLuceneGrammarParser.TILDE:
                    self.state = 136
                    self.term_modifier()


                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class FieldContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.FieldContext, self).__init__(parent, invokingState)
            self.parser = parser

        def TERM_NORMAL(self):
            return self.getToken(StandardLuceneGrammarParser.TERM_NORMAL, 0)

        def COLON(self):
            return self.getToken(StandardLuceneGrammarParser.COLON, 0)

        def sep(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,0)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_field

        def enterRule(self, listener):
            if hasattr(listener, "enterField"):
                listener.enterField(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitField"):
                listener.exitField(self)




    def field(self):

        localctx = StandardLuceneGrammarParser.FieldContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_field)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 141
            self.match(StandardLuceneGrammarParser.TERM_NORMAL)
            self.state = 142
            self.match(StandardLuceneGrammarParser.COLON)
            self.state = 144
            _la = self._input.LA(1)
            if _la==StandardLuceneGrammarParser.WS:
                self.state = 143
                self.sep()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ValueContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.ValueContext, self).__init__(parent, invokingState)
            self.parser = parser

        def range_term(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.Range_termContext,0)


        def normal(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.NormalContext,0)


        def truncated(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.TruncatedContext,0)


        def quoted(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.QuotedContext,0)


        def quoted_truncated(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.Quoted_truncatedContext,0)


        def QMARK(self):
            return self.getToken(StandardLuceneGrammarParser.QMARK, 0)

        def anything(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.AnythingContext,0)


        def STAR(self):
            return self.getToken(StandardLuceneGrammarParser.STAR, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_value

        def enterRule(self, listener):
            if hasattr(listener, "enterValue"):
                listener.enterValue(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitValue"):
                listener.exitValue(self)




    def value(self):

        localctx = StandardLuceneGrammarParser.ValueContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_value)
        try:
            self.state = 154
            la_ = self._interp.adaptivePredict(self._input,20,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 146
                self.range_term()
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 147
                self.normal()
                pass

            elif la_ == 3:
                self.enterOuterAlt(localctx, 3)
                self.state = 148
                self.truncated()
                pass

            elif la_ == 4:
                self.enterOuterAlt(localctx, 4)
                self.state = 149
                self.quoted()
                pass

            elif la_ == 5:
                self.enterOuterAlt(localctx, 5)
                self.state = 150
                self.quoted_truncated()
                pass

            elif la_ == 6:
                self.enterOuterAlt(localctx, 6)
                self.state = 151
                self.match(StandardLuceneGrammarParser.QMARK)
                pass

            elif la_ == 7:
                self.enterOuterAlt(localctx, 7)
                self.state = 152
                self.anything()
                pass

            elif la_ == 8:
                self.enterOuterAlt(localctx, 8)
                self.state = 153
                self.match(StandardLuceneGrammarParser.STAR)
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class AnythingContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.AnythingContext, self).__init__(parent, invokingState)
            self.parser = parser

        def STAR(self, i=None):
            if i is None:
                return self.getTokens(StandardLuceneGrammarParser.STAR)
            else:
                return self.getToken(StandardLuceneGrammarParser.STAR, i)

        def COLON(self):
            return self.getToken(StandardLuceneGrammarParser.COLON, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_anything

        def enterRule(self, listener):
            if hasattr(listener, "enterAnything"):
                listener.enterAnything(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitAnything"):
                listener.exitAnything(self)




    def anything(self):

        localctx = StandardLuceneGrammarParser.AnythingContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_anything)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 156
            self.match(StandardLuceneGrammarParser.STAR)
            self.state = 157
            self.match(StandardLuceneGrammarParser.COLON)
            self.state = 158
            self.match(StandardLuceneGrammarParser.STAR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Two_sided_range_termContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.Two_sided_range_termContext, self).__init__(parent, invokingState)
            self.parser = parser
            self.start_type = None # Token
            self.a = None # Range_valueContext
            self.b = None # Range_valueContext
            self.end_type = None # Token

        def LBRACK(self):
            return self.getToken(StandardLuceneGrammarParser.LBRACK, 0)

        def LCURLY(self):
            return self.getToken(StandardLuceneGrammarParser.LCURLY, 0)

        def RBRACK(self):
            return self.getToken(StandardLuceneGrammarParser.RBRACK, 0)

        def RCURLY(self):
            return self.getToken(StandardLuceneGrammarParser.RCURLY, 0)

        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,i)


        def range_value(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.Range_valueContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.Range_valueContext,i)


        def TO(self):
            return self.getToken(StandardLuceneGrammarParser.TO, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_two_sided_range_term

        def enterRule(self, listener):
            if hasattr(listener, "enterTwo_sided_range_term"):
                listener.enterTwo_sided_range_term(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitTwo_sided_range_term"):
                listener.exitTwo_sided_range_term(self)




    def two_sided_range_term(self):

        localctx = StandardLuceneGrammarParser.Two_sided_range_termContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_two_sided_range_term)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 160
            localctx.start_type = self._input.LT(1)
            _la = self._input.LA(1)
            if not(_la==StandardLuceneGrammarParser.LBRACK or _la==StandardLuceneGrammarParser.LCURLY):
                localctx.start_type = self._errHandler.recoverInline(self)
            else:
                self.consume()
            self.state = 162
            _la = self._input.LA(1)
            if _la==StandardLuceneGrammarParser.WS:
                self.state = 161
                self.sep()


            self.state = 164
            localctx.a = self.range_value()
            self.state = 166
            la_ = self._interp.adaptivePredict(self._input,22,self._ctx)
            if la_ == 1:
                self.state = 165
                self.sep()


            self.state = 178
            _la = self._input.LA(1)
            if (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << StandardLuceneGrammarParser.STAR) | (1 << StandardLuceneGrammarParser.TO) | (1 << StandardLuceneGrammarParser.WS) | (1 << StandardLuceneGrammarParser.NUMBER) | (1 << StandardLuceneGrammarParser.DATE_TOKEN) | (1 << StandardLuceneGrammarParser.TERM_NORMAL) | (1 << StandardLuceneGrammarParser.TERM_TRUNCATED) | (1 << StandardLuceneGrammarParser.PHRASE) | (1 << StandardLuceneGrammarParser.PHRASE_ANYTHING))) != 0):
                self.state = 169
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.TO:
                    self.state = 168
                    self.match(StandardLuceneGrammarParser.TO)


                self.state = 172
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.WS:
                    self.state = 171
                    self.sep()


                self.state = 174
                localctx.b = self.range_value()
                self.state = 176
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.WS:
                    self.state = 175
                    self.sep()




            self.state = 180
            localctx.end_type = self._input.LT(1)
            _la = self._input.LA(1)
            if not(_la==StandardLuceneGrammarParser.RBRACK or _la==StandardLuceneGrammarParser.RCURLY):
                localctx.end_type = self._errHandler.recoverInline(self)
            else:
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Range_termContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.Range_termContext, self).__init__(parent, invokingState)
            self.parser = parser

        def two_sided_range_term(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.Two_sided_range_termContext,0)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_range_term

        def enterRule(self, listener):
            if hasattr(listener, "enterRange_term"):
                listener.enterRange_term(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitRange_term"):
                listener.exitRange_term(self)




    def range_term(self):

        localctx = StandardLuceneGrammarParser.Range_termContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_range_term)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 182
            self.two_sided_range_term()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Range_valueContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.Range_valueContext, self).__init__(parent, invokingState)
            self.parser = parser

        def truncated(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.TruncatedContext,0)


        def quoted(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.QuotedContext,0)


        def quoted_truncated(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.Quoted_truncatedContext,0)


        def date(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.DateContext,0)


        def normal(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.NormalContext,0)


        def STAR(self):
            return self.getToken(StandardLuceneGrammarParser.STAR, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_range_value

        def enterRule(self, listener):
            if hasattr(listener, "enterRange_value"):
                listener.enterRange_value(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitRange_value"):
                listener.exitRange_value(self)




    def range_value(self):

        localctx = StandardLuceneGrammarParser.Range_valueContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_range_value)
        try:
            self.state = 190
            token = self._input.LA(1)
            if token in [StandardLuceneGrammarParser.TERM_TRUNCATED]:
                self.enterOuterAlt(localctx, 1)
                self.state = 184
                self.truncated()

            elif token in [StandardLuceneGrammarParser.PHRASE]:
                self.enterOuterAlt(localctx, 2)
                self.state = 185
                self.quoted()

            elif token in [StandardLuceneGrammarParser.PHRASE_ANYTHING]:
                self.enterOuterAlt(localctx, 3)
                self.state = 186
                self.quoted_truncated()

            elif token in [StandardLuceneGrammarParser.DATE_TOKEN]:
                self.enterOuterAlt(localctx, 4)
                self.state = 187
                self.date()

            elif token in [StandardLuceneGrammarParser.NUMBER, StandardLuceneGrammarParser.TERM_NORMAL]:
                self.enterOuterAlt(localctx, 5)
                self.state = 188
                self.normal()

            elif token in [StandardLuceneGrammarParser.STAR]:
                self.enterOuterAlt(localctx, 6)
                self.state = 189
                self.match(StandardLuceneGrammarParser.STAR)

            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Multi_valueContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.Multi_valueContext, self).__init__(parent, invokingState)
            self.parser = parser

        def LPAREN(self):
            return self.getToken(StandardLuceneGrammarParser.LPAREN, 0)

        def clauseDefault(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.ClauseDefaultContext,0)


        def RPAREN(self):
            return self.getToken(StandardLuceneGrammarParser.RPAREN, 0)

        def sep(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,0)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_multi_value

        def enterRule(self, listener):
            if hasattr(listener, "enterMulti_value"):
                listener.enterMulti_value(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitMulti_value"):
                listener.exitMulti_value(self)




    def multi_value(self):

        localctx = StandardLuceneGrammarParser.Multi_valueContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_multi_value)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 192
            self.match(StandardLuceneGrammarParser.LPAREN)
            self.state = 193
            self.clauseDefault()
            self.state = 195
            _la = self._input.LA(1)
            if _la==StandardLuceneGrammarParser.WS:
                self.state = 194
                self.sep()


            self.state = 197
            self.match(StandardLuceneGrammarParser.RPAREN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class NormalContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.NormalContext, self).__init__(parent, invokingState)
            self.parser = parser

        def TERM_NORMAL(self):
            return self.getToken(StandardLuceneGrammarParser.TERM_NORMAL, 0)

        def NUMBER(self):
            return self.getToken(StandardLuceneGrammarParser.NUMBER, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_normal

        def enterRule(self, listener):
            if hasattr(listener, "enterNormal"):
                listener.enterNormal(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitNormal"):
                listener.exitNormal(self)




    def normal(self):

        localctx = StandardLuceneGrammarParser.NormalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_normal)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 199
            _la = self._input.LA(1)
            if not(_la==StandardLuceneGrammarParser.NUMBER or _la==StandardLuceneGrammarParser.TERM_NORMAL):
                self._errHandler.recoverInline(self)
            else:
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class TruncatedContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.TruncatedContext, self).__init__(parent, invokingState)
            self.parser = parser

        def TERM_TRUNCATED(self):
            return self.getToken(StandardLuceneGrammarParser.TERM_TRUNCATED, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_truncated

        def enterRule(self, listener):
            if hasattr(listener, "enterTruncated"):
                listener.enterTruncated(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitTruncated"):
                listener.exitTruncated(self)




    def truncated(self):

        localctx = StandardLuceneGrammarParser.TruncatedContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_truncated)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 201
            self.match(StandardLuceneGrammarParser.TERM_TRUNCATED)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Quoted_truncatedContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.Quoted_truncatedContext, self).__init__(parent, invokingState)
            self.parser = parser

        def PHRASE_ANYTHING(self):
            return self.getToken(StandardLuceneGrammarParser.PHRASE_ANYTHING, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_quoted_truncated

        def enterRule(self, listener):
            if hasattr(listener, "enterQuoted_truncated"):
                listener.enterQuoted_truncated(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitQuoted_truncated"):
                listener.exitQuoted_truncated(self)




    def quoted_truncated(self):

        localctx = StandardLuceneGrammarParser.Quoted_truncatedContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_quoted_truncated)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 203
            self.match(StandardLuceneGrammarParser.PHRASE_ANYTHING)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class QuotedContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.QuotedContext, self).__init__(parent, invokingState)
            self.parser = parser

        def PHRASE(self):
            return self.getToken(StandardLuceneGrammarParser.PHRASE, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_quoted

        def enterRule(self, listener):
            if hasattr(listener, "enterQuoted"):
                listener.enterQuoted(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitQuoted"):
                listener.exitQuoted(self)




    def quoted(self):

        localctx = StandardLuceneGrammarParser.QuotedContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_quoted)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 205
            self.match(StandardLuceneGrammarParser.PHRASE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ModifierContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.ModifierContext, self).__init__(parent, invokingState)
            self.parser = parser

        def PLUS(self):
            return self.getToken(StandardLuceneGrammarParser.PLUS, 0)

        def MINUS(self):
            return self.getToken(StandardLuceneGrammarParser.MINUS, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_modifier

        def enterRule(self, listener):
            if hasattr(listener, "enterModifier"):
                listener.enterModifier(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitModifier"):
                listener.exitModifier(self)




    def modifier(self):

        localctx = StandardLuceneGrammarParser.ModifierContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_modifier)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 207
            _la = self._input.LA(1)
            if not(_la==StandardLuceneGrammarParser.PLUS or _la==StandardLuceneGrammarParser.MINUS):
                self._errHandler.recoverInline(self)
            else:
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Term_modifierContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.Term_modifierContext, self).__init__(parent, invokingState)
            self.parser = parser

        def boost(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.BoostContext,0)


        def fuzzy(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.FuzzyContext,0)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_term_modifier

        def enterRule(self, listener):
            if hasattr(listener, "enterTerm_modifier"):
                listener.enterTerm_modifier(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitTerm_modifier"):
                listener.exitTerm_modifier(self)




    def term_modifier(self):

        localctx = StandardLuceneGrammarParser.Term_modifierContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_term_modifier)
        self._la = 0 # Token type
        try:
            self.state = 217
            token = self._input.LA(1)
            if token in [StandardLuceneGrammarParser.CARAT]:
                self.enterOuterAlt(localctx, 1)
                self.state = 209
                self.boost()
                self.state = 211
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.TILDE:
                    self.state = 210
                    self.fuzzy()



            elif token in [StandardLuceneGrammarParser.TILDE]:
                self.enterOuterAlt(localctx, 2)
                self.state = 213
                self.fuzzy()
                self.state = 215
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.CARAT:
                    self.state = 214
                    self.boost()



            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class BoostContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.BoostContext, self).__init__(parent, invokingState)
            self.parser = parser

        def CARAT(self):
            return self.getToken(StandardLuceneGrammarParser.CARAT, 0)

        def NUMBER(self):
            return self.getToken(StandardLuceneGrammarParser.NUMBER, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_boost

        def enterRule(self, listener):
            if hasattr(listener, "enterBoost"):
                listener.enterBoost(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitBoost"):
                listener.exitBoost(self)




    def boost(self):

        localctx = StandardLuceneGrammarParser.BoostContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_boost)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 219
            self.match(StandardLuceneGrammarParser.CARAT)
            self.state = 221
            la_ = self._interp.adaptivePredict(self._input,32,self._ctx)
            if la_ == 1:
                self.state = 220
                self.match(StandardLuceneGrammarParser.NUMBER)


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class FuzzyContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.FuzzyContext, self).__init__(parent, invokingState)
            self.parser = parser

        def TILDE(self):
            return self.getToken(StandardLuceneGrammarParser.TILDE, 0)

        def NUMBER(self):
            return self.getToken(StandardLuceneGrammarParser.NUMBER, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_fuzzy

        def enterRule(self, listener):
            if hasattr(listener, "enterFuzzy"):
                listener.enterFuzzy(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitFuzzy"):
                listener.exitFuzzy(self)




    def fuzzy(self):

        localctx = StandardLuceneGrammarParser.FuzzyContext(self, self._ctx, self.state)
        self.enterRule(localctx, 42, self.RULE_fuzzy)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 223
            self.match(StandardLuceneGrammarParser.TILDE)
            self.state = 225
            la_ = self._interp.adaptivePredict(self._input,33,self._ctx)
            if la_ == 1:
                self.state = 224
                self.match(StandardLuceneGrammarParser.NUMBER)


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Not_Context(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.Not_Context, self).__init__(parent, invokingState)
            self.parser = parser

        def AND(self):
            return self.getToken(StandardLuceneGrammarParser.AND, 0)

        def NOT(self):
            return self.getToken(StandardLuceneGrammarParser.NOT, 0)

        def sep(self, i=None):
            if i is None:
                return self.getTypedRuleContexts(StandardLuceneGrammarParser.SepContext)
            else:
                return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,i)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_not_

        def enterRule(self, listener):
            if hasattr(listener, "enterNot_"):
                listener.enterNot_(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitNot_"):
                listener.exitNot_(self)




    def not_(self):

        localctx = StandardLuceneGrammarParser.Not_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 44, self.RULE_not_)
        self._la = 0 # Token type
        try:
            self.state = 239
            la_ = self._interp.adaptivePredict(self._input,37,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 228
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.WS:
                    self.state = 227
                    self.sep()


                self.state = 230
                self.match(StandardLuceneGrammarParser.AND)
                self.state = 232
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.WS:
                    self.state = 231
                    self.sep()


                self.state = 234
                self.match(StandardLuceneGrammarParser.NOT)
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 236
                _la = self._input.LA(1)
                if _la==StandardLuceneGrammarParser.WS:
                    self.state = 235
                    self.sep()


                self.state = 238
                self.match(StandardLuceneGrammarParser.NOT)
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class And_Context(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.And_Context, self).__init__(parent, invokingState)
            self.parser = parser

        def AND(self):
            return self.getToken(StandardLuceneGrammarParser.AND, 0)

        def sep(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,0)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_and_

        def enterRule(self, listener):
            if hasattr(listener, "enterAnd_"):
                listener.enterAnd_(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitAnd_"):
                listener.exitAnd_(self)




    def and_(self):

        localctx = StandardLuceneGrammarParser.And_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 46, self.RULE_and_)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 242
            _la = self._input.LA(1)
            if _la==StandardLuceneGrammarParser.WS:
                self.state = 241
                self.sep()


            self.state = 244
            self.match(StandardLuceneGrammarParser.AND)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Or_Context(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.Or_Context, self).__init__(parent, invokingState)
            self.parser = parser

        def OR(self):
            return self.getToken(StandardLuceneGrammarParser.OR, 0)

        def sep(self):
            return self.getTypedRuleContext(StandardLuceneGrammarParser.SepContext,0)


        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_or_

        def enterRule(self, listener):
            if hasattr(listener, "enterOr_"):
                listener.enterOr_(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitOr_"):
                listener.exitOr_(self)




    def or_(self):

        localctx = StandardLuceneGrammarParser.Or_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 48, self.RULE_or_)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 247
            _la = self._input.LA(1)
            if _la==StandardLuceneGrammarParser.WS:
                self.state = 246
                self.sep()


            self.state = 249
            self.match(StandardLuceneGrammarParser.OR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class DateContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.DateContext, self).__init__(parent, invokingState)
            self.parser = parser

        def DATE_TOKEN(self):
            return self.getToken(StandardLuceneGrammarParser.DATE_TOKEN, 0)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_date

        def enterRule(self, listener):
            if hasattr(listener, "enterDate"):
                listener.enterDate(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitDate"):
                listener.exitDate(self)




    def date(self):

        localctx = StandardLuceneGrammarParser.DateContext(self, self._ctx, self.state)
        self.enterRule(localctx, 50, self.RULE_date)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 251
            self.match(StandardLuceneGrammarParser.DATE_TOKEN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class SepContext(ParserRuleContext):

        def __init__(self, parser, parent=None, invokingState=-1):
            super(StandardLuceneGrammarParser.SepContext, self).__init__(parent, invokingState)
            self.parser = parser

        def WS(self, i=None):
            if i is None:
                return self.getTokens(StandardLuceneGrammarParser.WS)
            else:
                return self.getToken(StandardLuceneGrammarParser.WS, i)

        def getRuleIndex(self):
            return StandardLuceneGrammarParser.RULE_sep

        def enterRule(self, listener):
            if hasattr(listener, "enterSep"):
                listener.enterSep(self)

        def exitRule(self, listener):
            if hasattr(listener, "exitSep"):
                listener.exitSep(self)




    def sep(self):

        localctx = StandardLuceneGrammarParser.SepContext(self, self._ctx, self.state)
        self.enterRule(localctx, 52, self.RULE_sep)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 254 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 253
                    self.match(StandardLuceneGrammarParser.WS)

                else:
                    raise NoViableAltException(self)
                self.state = 256 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,40,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





